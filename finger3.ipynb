{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialización del ambiente de Spark y la SparkSession\n",
    "import pyspark\n",
    "\n",
    "sc = pyspark.SparkContext.getOrCreate()\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Spark SQL Finger 3\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flights = spark.read.csv(\"data/flights.csv\",\n",
    "                    sep=\",\", inferSchema=\"true\", header=\"true\")\n",
    "df_flights.createOrReplaceTempView(\"flights\")\n",
    "\n",
    "df_airlines = spark.read.csv(\"data/airlines.csv\",\n",
    "                    sep=\",\", inferSchema=\"true\", header=\"true\")\n",
    "df_airlines.createOrReplaceTempView(\"airlines\")\n",
    "\n",
    "df_airports = spark.read.csv(\"data/airports.csv\",\n",
    "                    sep=\",\", inferSchema=\"true\", header=\"true\")\n",
    "df_airports.createOrReplaceTempView(\"airports\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veamos qué columnas tenemos en cada tabla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- YEAR: integer (nullable = true)\n",
      " |-- MONTH: integer (nullable = true)\n",
      " |-- DAY: integer (nullable = true)\n",
      " |-- DAY_OF_WEEK: integer (nullable = true)\n",
      " |-- AIRLINE: string (nullable = true)\n",
      " |-- FLIGHT_NUMBER: integer (nullable = true)\n",
      " |-- TAIL_NUMBER: string (nullable = true)\n",
      " |-- ORIGIN_AIRPORT: string (nullable = true)\n",
      " |-- DESTINATION_AIRPORT: string (nullable = true)\n",
      " |-- SCHEDULED_DEPARTURE: integer (nullable = true)\n",
      " |-- DEPARTURE_TIME: integer (nullable = true)\n",
      " |-- DEPARTURE_DELAY: integer (nullable = true)\n",
      " |-- TAXI_OUT: integer (nullable = true)\n",
      " |-- WHEELS_OFF: integer (nullable = true)\n",
      " |-- SCHEDULED_TIME: integer (nullable = true)\n",
      " |-- ELAPSED_TIME: integer (nullable = true)\n",
      " |-- AIR_TIME: integer (nullable = true)\n",
      " |-- DISTANCE: integer (nullable = true)\n",
      " |-- WHEELS_ON: integer (nullable = true)\n",
      " |-- TAXI_IN: integer (nullable = true)\n",
      " |-- SCHEDULED_ARRIVAL: integer (nullable = true)\n",
      " |-- ARRIVAL_TIME: integer (nullable = true)\n",
      " |-- ARRIVAL_DELAY: integer (nullable = true)\n",
      " |-- DIVERTED: integer (nullable = true)\n",
      " |-- CANCELLED: integer (nullable = true)\n",
      " |-- CANCELLATION_REASON: string (nullable = true)\n",
      " |-- AIR_SYSTEM_DELAY: integer (nullable = true)\n",
      " |-- SECURITY_DELAY: integer (nullable = true)\n",
      " |-- AIRLINE_DELAY: integer (nullable = true)\n",
      " |-- LATE_AIRCRAFT_DELAY: integer (nullable = true)\n",
      " |-- WEATHER_DELAY: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_flights.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- IATA_CODE: string (nullable = true)\n",
      " |-- AIRLINE: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_airlines.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- IATA_CODE: string (nullable = true)\n",
      " |-- AIRPORT: string (nullable = true)\n",
      " |-- CITY: string (nullable = true)\n",
      " |-- STATE: string (nullable = true)\n",
      " |-- COUNTRY: string (nullable = true)\n",
      " |-- LATITUDE: double (nullable = true)\n",
      " |-- LONGITUDE: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_airports.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punto 1: Mostrar los 5 aeropuertos de origen que tienen mayor cantidad de cancelaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|      origin_airport|total_cancelled|\n",
      "+--------------------+---------------+\n",
      "|Chicago O'Hare In...|           8548|\n",
      "|Dallas/Fort Worth...|           6254|\n",
      "|LaGuardia Airport...|           4531|\n",
      "|Newark Liberty In...|           3110|\n",
      "|Gen. Edward Lawre...|           2654|\n",
      "+--------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top5_origin_airports = spark.sql(\"SELECT airports.AIRPORT as origin_airport, COUNT(*) as total_cancelled\\\n",
    "                                FROM flights INNER JOIN airports ON flights.ORIGIN_AIRPORT = airports.IATA_CODE\\\n",
    "                                WHERE CANCELLED = 1 GROUP BY airports.AIRPORT ORDER BY total_cancelled DESC\")\n",
    "top5_origin_airports.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punto 2: Mostrar el nombre de aerolíneas y la cantidad de vuelos desde Atlanta (ATL) a Los Ángeles (LAX) ordenadas por cantidad de vuelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+\n",
      "|        airline_name|total_flights_atl_lax|\n",
      "+--------------------+---------------------+\n",
      "|Delta Air Lines Inc.|                 3624|\n",
      "|Southwest Airline...|                  962|\n",
      "|American Airlines...|                  765|\n",
      "|Frontier Airlines...|                  215|\n",
      "|    Spirit Air Lines|                  103|\n",
      "+--------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT airlines.AIRLINE as airline_name, COUNT(flights.FLIGHT_NUMBER) as total_flights_atl_lax\\\n",
    "                                    FROM flights INNER JOIN airlines ON flights.AIRLINE = airlines.IATA_CODE\\\n",
    "                                    WHERE flights.ORIGIN_AIRPORT = 'ATL' AND flights.DESTINATION_AIRPORT = 'LAX'\\\n",
    "                                    GROUP BY airlines.AIRLINE ORDER BY total_flights_atl_lax DESC\"\n",
    "airlines_flights_atl_lax = spark.sql(query)\n",
    "airlines_flights_atl_lax.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punto 3: Analizar la query del punto 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Sort ['total_flights_atl_lax DESC NULLS LAST], true\n",
      "+- 'Aggregate ['airlines.AIRLINE], ['airlines.AIRLINE AS airline_name#152, 'COUNT('flights.FLIGHT_NUMBER) AS total_flights_atl_lax#153]\n",
      "   +- 'Filter (('flights.ORIGIN_AIRPORT = ATL) && ('flights.DESTINATION_AIRPORT = LAX))\n",
      "      +- 'Join Inner, ('flights.AIRLINE = 'airlines.IATA_CODE)\n",
      "         :- 'UnresolvedRelation `flights`\n",
      "         +- 'UnresolvedRelation `airlines`\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "airline_name: string, total_flights_atl_lax: bigint\n",
      "Sort [total_flights_atl_lax#153L DESC NULLS LAST], true\n",
      "+- Aggregate [AIRLINE#83], [AIRLINE#83 AS airline_name#152, count(FLIGHT_NUMBER#15) AS total_flights_atl_lax#153L]\n",
      "   +- Filter ((ORIGIN_AIRPORT#17 = ATL) && (DESTINATION_AIRPORT#18 = LAX))\n",
      "      +- Join Inner, (AIRLINE#14 = IATA_CODE#82)\n",
      "         :- SubqueryAlias flights\n",
      "         :  +- Relation[YEAR#10,MONTH#11,DAY#12,DAY_OF_WEEK#13,AIRLINE#14,FLIGHT_NUMBER#15,TAIL_NUMBER#16,ORIGIN_AIRPORT#17,DESTINATION_AIRPORT#18,SCHEDULED_DEPARTURE#19,DEPARTURE_TIME#20,DEPARTURE_DELAY#21,TAXI_OUT#22,WHEELS_OFF#23,SCHEDULED_TIME#24,ELAPSED_TIME#25,AIR_TIME#26,DISTANCE#27,WHEELS_ON#28,TAXI_IN#29,SCHEDULED_ARRIVAL#30,ARRIVAL_TIME#31,ARRIVAL_DELAY#32,DIVERTED#33,... 7 more fields] csv\n",
      "         +- SubqueryAlias airlines\n",
      "            +- Relation[IATA_CODE#82,AIRLINE#83] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Sort [total_flights_atl_lax#153L DESC NULLS LAST], true\n",
      "+- Aggregate [AIRLINE#83], [AIRLINE#83 AS airline_name#152, count(FLIGHT_NUMBER#15) AS total_flights_atl_lax#153L]\n",
      "   +- Project [FLIGHT_NUMBER#15, AIRLINE#83]\n",
      "      +- Join Inner, (AIRLINE#14 = IATA_CODE#82)\n",
      "         :- Project [AIRLINE#14, FLIGHT_NUMBER#15]\n",
      "         :  +- Filter ((((isnotnull(ORIGIN_AIRPORT#17) && isnotnull(DESTINATION_AIRPORT#18)) && (ORIGIN_AIRPORT#17 = ATL)) && (DESTINATION_AIRPORT#18 = LAX)) && isnotnull(AIRLINE#14))\n",
      "         :     +- Relation[YEAR#10,MONTH#11,DAY#12,DAY_OF_WEEK#13,AIRLINE#14,FLIGHT_NUMBER#15,TAIL_NUMBER#16,ORIGIN_AIRPORT#17,DESTINATION_AIRPORT#18,SCHEDULED_DEPARTURE#19,DEPARTURE_TIME#20,DEPARTURE_DELAY#21,TAXI_OUT#22,WHEELS_OFF#23,SCHEDULED_TIME#24,ELAPSED_TIME#25,AIR_TIME#26,DISTANCE#27,WHEELS_ON#28,TAXI_IN#29,SCHEDULED_ARRIVAL#30,ARRIVAL_TIME#31,ARRIVAL_DELAY#32,DIVERTED#33,... 7 more fields] csv\n",
      "         +- Filter isnotnull(IATA_CODE#82)\n",
      "            +- Relation[IATA_CODE#82,AIRLINE#83] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "*(4) Sort [total_flights_atl_lax#153L DESC NULLS LAST], true, 0\n",
      "+- Exchange rangepartitioning(total_flights_atl_lax#153L DESC NULLS LAST, 200)\n",
      "   +- *(3) HashAggregate(keys=[AIRLINE#83], functions=[count(FLIGHT_NUMBER#15)], output=[airline_name#152, total_flights_atl_lax#153L])\n",
      "      +- Exchange hashpartitioning(AIRLINE#83, 200)\n",
      "         +- *(2) HashAggregate(keys=[AIRLINE#83], functions=[partial_count(FLIGHT_NUMBER#15)], output=[AIRLINE#83, count#159L])\n",
      "            +- *(2) Project [FLIGHT_NUMBER#15, AIRLINE#83]\n",
      "               +- *(2) BroadcastHashJoin [AIRLINE#14], [IATA_CODE#82], Inner, BuildRight\n",
      "                  :- *(2) Project [AIRLINE#14, FLIGHT_NUMBER#15]\n",
      "                  :  +- *(2) Filter ((((isnotnull(ORIGIN_AIRPORT#17) && isnotnull(DESTINATION_AIRPORT#18)) && (ORIGIN_AIRPORT#17 = ATL)) && (DESTINATION_AIRPORT#18 = LAX)) && isnotnull(AIRLINE#14))\n",
      "                  :     +- *(2) FileScan csv [AIRLINE#14,FLIGHT_NUMBER#15,ORIGIN_AIRPORT#17,DESTINATION_AIRPORT#18] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/alawichu/Desktop/Repositorios/7506-Fingers/data/flights.csv], PartitionFilters: [], PushedFilters: [IsNotNull(ORIGIN_AIRPORT), IsNotNull(DESTINATION_AIRPORT), EqualTo(ORIGIN_AIRPORT,ATL), EqualTo(..., ReadSchema: struct<AIRLINE:string,FLIGHT_NUMBER:int,ORIGIN_AIRPORT:string,DESTINATION_AIRPORT:string>\n",
      "                  +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]))\n",
      "                     +- *(1) Project [IATA_CODE#82, AIRLINE#83]\n",
      "                        +- *(1) Filter isnotnull(IATA_CODE#82)\n",
      "                           +- *(1) FileScan csv [IATA_CODE#82,AIRLINE#83] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/alawichu/Desktop/Repositorios/7506-Fingers/data/airlines.csv], PartitionFilters: [], PushedFilters: [IsNotNull(IATA_CODE)], ReadSchema: struct<IATA_CODE:string,AIRLINE:string>\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Efectivamente se realiza una optimización lógica, en la etapa de análisis del plan a ejecutar, en particular es un filter pushdown.\n",
    "Como se puede observar en el Optimized Logical Plan, el filtrado por origen y destino se hace antes que el JOIN (además de que ahora se verifica que los campos no sean nulos), a diferencia de lo propuesto en el Analyzed Plan en donde se ejecutaba primero el JOIN y luego el FILTER.\n",
    "De esta forma se puede trabajar con menos datos en la unión de las tablas.\n",
    "\n",
    "2. El Join _físico_  es un BroadcastHashJoin. Esto se da en la etapa de Physical Planning, en la cual Catalyst va a armar distintos planes, evaluarlos según su _costo_ y eventualmente seleccionar el que tenga mejor performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
